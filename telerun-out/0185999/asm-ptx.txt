
Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_89
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = 

//
//
//
//
//
//

.version 8.7
.target sm_89
.address_size 64

//

.visible .entry _Z25mandelbrot_gpu_vector_ilpjjPj(
.param .u32 _Z25mandelbrot_gpu_vector_ilpjjPj_param_0,
.param .u32 _Z25mandelbrot_gpu_vector_ilpjjPj_param_1,
.param .u64 _Z25mandelbrot_gpu_vector_ilpjjPj_param_2
)
{
.reg .pred %p<22>;
.reg .b16 %rs<47>;
.reg .f32 %f<117>;
.reg .b32 %r<29>;
.reg .b64 %rd<19>;


ld.param.u32 %r13, [_Z25mandelbrot_gpu_vector_ilpjjPj_param_0];
ld.param.u32 %r14, [_Z25mandelbrot_gpu_vector_ilpjjPj_param_1];
ld.param.u64 %rd9, [_Z25mandelbrot_gpu_vector_ilpjjPj_param_2];
cvt.u64.u32 %rd1, %r13;
setp.eq.s32 %p1, %r13, 0;
@%p1 bra $L__BB0_20;

mov.u32 %r15, %tid.x;
cvt.u64.u32 %rd2, %r15;
cvt.rn.f32.u32 %f1, %r13;
cvta.to.global.u64 %rd3, %rd9;
mov.u64 %rd17, 0;
cvt.u32.u64 %r16, %rd2;

$L__BB0_2:
setp.ge.u32 %p2, %r16, %r13;
@%p2 bra $L__BB0_19;

cvt.rn.f32.u64 %f43, %rd17;
div.approx.ftz.f32 %f44, %f43, %f1;
fma.rn.ftz.f32 %f2, %f44, 0f38D1B717, 0f3E06F043;
mul.lo.s64 %rd5, %rd17, %rd1;
mov.u64 %rd18, %rd2;

$L__BB0_4:
cvt.rn.f32.u64 %f57, %rd18;
div.approx.ftz.f32 %f58, %f57, %f1;
fma.rn.ftz.f32 %f3, %f58, 0f38D1B717, 0fBF3E62B9;
add.s64 %rd11, %rd18, 32;
cvt.rn.f32.u64 %f59, %rd11;
div.approx.ftz.f32 %f60, %f59, %f1;
fma.rn.ftz.f32 %f4, %f60, 0f38D1B717, 0fBF3E62B9;
add.s64 %rd12, %rd18, 64;
cvt.rn.f32.u64 %f61, %rd12;
div.approx.ftz.f32 %f62, %f61, %f1;
fma.rn.ftz.f32 %f5, %f62, 0f38D1B717, 0fBF3E62B9;
add.s64 %rd13, %rd18, 96;
cvt.rn.f32.u64 %f63, %rd13;
div.approx.ftz.f32 %f64, %f63, %f1;
fma.rn.ftz.f32 %f6, %f64, 0f38D1B717, 0fBF3E62B9;
mov.u32 %r21, 0;
mov.u16 %rs35, 1;
mov.f32 %f93, 0f00000000;
mov.f32 %f94, %f93;
mov.f32 %f95, %f93;
mov.f32 %f105, %f93;
mov.f32 %f97, %f93;
mov.f32 %f98, %f93;
mov.f32 %f99, %f93;
mov.f32 %f106, %f93;
mov.f32 %f101, %f93;
mov.f32 %f102, %f93;
mov.f32 %f103, %f93;
mov.f32 %f107, %f93;
mov.u16 %rs43, %rs35;
mov.u16 %rs37, %rs35;
mov.u16 %rs39, %rs35;
mov.u32 %r22, %r21;
mov.u32 %r23, %r21;
mov.u32 %r25, %r21;

$L__BB0_5:
mov.u16 %rs4, %rs39;
mov.u16 %rs3, %rs37;
mov.u16 %rs2, %rs43;
mov.u16 %rs1, %rs35;
and.b16 %rs19, %rs4, 255;
setp.eq.s16 %p3, %rs19, 0;
mov.u16 %rs37, 0;
mov.u16 %rs39, %rs37;
mov.u16 %rs42, %rs37;
@%p3 bra $L__BB0_8;

add.ftz.f32 %f65, %f105, %f106;
setp.gtu.ftz.f32 %p4, %f65, 0f40800000;
setp.ge.u32 %p5, %r25, %r14;
or.pred %p6, %p4, %p5;
@%p6 bra $L__BB0_8;

sub.ftz.f32 %f66, %f105, %f106;
add.ftz.f32 %f67, %f66, %f3;
sub.ftz.f32 %f68, %f107, %f105;
sub.ftz.f32 %f69, %f68, %f106;
add.ftz.f32 %f70, %f69, %f2;
mul.ftz.f32 %f105, %f67, %f67;
mul.ftz.f32 %f106, %f70, %f70;
add.ftz.f32 %f71, %f67, %f70;
mul.ftz.f32 %f107, %f71, %f71;
add.s32 %r25, %r25, 1;
mov.u16 %rs42, 1;
mov.u16 %rs39, %rs4;

$L__BB0_8:
and.b16 %rs24, %rs3, 255;
setp.eq.s16 %p7, %rs24, 0;
@%p7 bra $L__BB0_11;

add.ftz.f32 %f72, %f95, %f99;
setp.gtu.ftz.f32 %p8, %f72, 0f40800000;
setp.ge.u32 %p9, %r23, %r14;
or.pred %p10, %p8, %p9;
@%p10 bra $L__BB0_11;

sub.ftz.f32 %f73, %f95, %f99;
add.ftz.f32 %f74, %f73, %f4;
sub.ftz.f32 %f75, %f103, %f95;
sub.ftz.f32 %f76, %f75, %f99;
add.ftz.f32 %f77, %f76, %f2;
mul.ftz.f32 %f95, %f74, %f74;
mul.ftz.f32 %f99, %f77, %f77;
add.ftz.f32 %f78, %f74, %f77;
mul.ftz.f32 %f103, %f78, %f78;
add.s32 %r23, %r23, 1;
mov.u16 %rs42, 1;
mov.u16 %rs37, %rs3;

$L__BB0_11:
and.b16 %rs28, %rs2, 255;
setp.eq.s16 %p11, %rs28, 0;
mov.u16 %rs35, 0;
mov.u16 %rs43, %rs35;
@%p11 bra $L__BB0_14;

add.ftz.f32 %f79, %f94, %f98;
setp.gtu.ftz.f32 %p12, %f79, 0f40800000;
setp.ge.u32 %p13, %r22, %r14;
or.pred %p14, %p12, %p13;
@%p14 bra $L__BB0_14;

sub.ftz.f32 %f80, %f94, %f98;
add.ftz.f32 %f81, %f80, %f5;
sub.ftz.f32 %f82, %f102, %f94;
sub.ftz.f32 %f83, %f82, %f98;
add.ftz.f32 %f84, %f83, %f2;
mul.ftz.f32 %f94, %f81, %f81;
mul.ftz.f32 %f98, %f84, %f84;
add.ftz.f32 %f85, %f81, %f84;
mul.ftz.f32 %f102, %f85, %f85;
add.s32 %r22, %r22, 1;
mov.u16 %rs42, 1;
mov.u16 %rs43, %rs2;

$L__BB0_14:
and.b16 %rs32, %rs1, 255;
setp.eq.s16 %p15, %rs32, 0;
@%p15 bra $L__BB0_17;

add.ftz.f32 %f86, %f93, %f97;
setp.gtu.ftz.f32 %p16, %f86, 0f40800000;
setp.ge.u32 %p17, %r21, %r14;
or.pred %p18, %p16, %p17;
@%p18 bra $L__BB0_17;

sub.ftz.f32 %f87, %f93, %f97;
add.ftz.f32 %f88, %f87, %f6;
sub.ftz.f32 %f89, %f101, %f93;
sub.ftz.f32 %f90, %f89, %f97;
add.ftz.f32 %f91, %f90, %f2;
mul.ftz.f32 %f93, %f88, %f88;
mul.ftz.f32 %f97, %f91, %f91;
add.ftz.f32 %f92, %f88, %f91;
mul.ftz.f32 %f101, %f92, %f92;
add.s32 %r21, %r21, 1;
mov.u16 %rs42, 1;
mov.u16 %rs35, %rs1;

$L__BB0_17:
setp.ne.s16 %p19, %rs42, 0;
@%p19 bra $L__BB0_5;

add.s64 %rd14, %rd18, %rd5;
shl.b64 %rd15, %rd14, 2;
add.s64 %rd16, %rd3, %rd15;
st.global.u32 [%rd16], %r25;
st.global.u32 [%rd16+128], %r23;
st.global.u32 [%rd16+256], %r22;
st.global.u32 [%rd16+384], %r21;
add.s64 %rd18, %rd18, 128;
setp.lt.u64 %p20, %rd18, %rd1;
@%p20 bra $L__BB0_4;

$L__BB0_19:
add.s64 %rd17, %rd17, 1;
setp.lt.u64 %p21, %rd17, %rd1;
@%p21 bra $L__BB0_2;

$L__BB0_20:
ret;

}
//
.visible .entry _Z31mandelbrot_gpu_vector_multicorejjPj(
.param .u32 _Z31mandelbrot_gpu_vector_multicorejjPj_param_0,
.param .u32 _Z31mandelbrot_gpu_vector_multicorejjPj_param_1,
.param .u64 _Z31mandelbrot_gpu_vector_multicorejjPj_param_2
)
{



ret;

}
//
.visible .entry _Z53mandelbrot_gpu_vector_multicore_multithread_single_smjjPj(
.param .u32 _Z53mandelbrot_gpu_vector_multicore_multithread_single_smjjPj_param_0,
.param .u32 _Z53mandelbrot_gpu_vector_multicore_multithread_single_smjjPj_param_1,
.param .u64 _Z53mandelbrot_gpu_vector_multicore_multithread_single_smjjPj_param_2
)
{



ret;

}
//
.visible .entry _Z48mandelbrot_gpu_vector_multicore_multithread_fulljjPj(
.param .u32 _Z48mandelbrot_gpu_vector_multicore_multithread_fulljjPj_param_0,
.param .u32 _Z48mandelbrot_gpu_vector_multicore_multithread_fulljjPj_param_1,
.param .u64 _Z48mandelbrot_gpu_vector_multicore_multithread_fulljjPj_param_2
)
{



ret;

}
//
.visible .entry _Z52mandelbrot_gpu_vector_multicore_multithread_full_ilpjjPj(
.param .u32 _Z52mandelbrot_gpu_vector_multicore_multithread_full_ilpjjPj_param_0,
.param .u32 _Z52mandelbrot_gpu_vector_multicore_multithread_full_ilpjjPj_param_1,
.param .u64 _Z52mandelbrot_gpu_vector_multicore_multithread_full_ilpjjPj_param_2
)
{



ret;

}


