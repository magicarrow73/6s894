
Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_89
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = 

//
//
//
//
//
//

.version 8.7
.target sm_89
.address_size 64

//
.extern .shared .align 16 .b8 shmem[];

.visible .entry _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 200;
@%p1 bra $L__BB0_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB0_2:
setp.gt.s32 %p2, %r2, 200;
@%p2 bra $L__BB0_12;

mul.lo.s32 %r8, %r19, 201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB0_4:
setp.eq.s32 %p3, %r20, 200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB0_11;

mov.f32 %f9, 0f43480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB0_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5B2;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE149C;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB0_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB0_11;

setp.ne.s32 %p19, %r19, 100;
setp.ne.s32 %p20, %r20, 33;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB0_10;
bra.uni $L__BB0_9;

$L__BB0_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f43480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB0_11;

$L__BB0_9:
mov.f32 %f46, %f4;

$L__BB0_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 201;
@%p22 bra $L__BB0_4;

$L__BB0_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 201;
@%p23 bra $L__BB0_2;

$L__BB0_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<73>;
.reg .b16 %rs<9>;
.reg .f32 %f<147>;
.reg .b32 %r<67>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r20, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r21, %r20, 1;
sub.s32 %r22, %r2, %r21;
mov.u32 %r23, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r24, %r4, %r20;
mad.lo.s32 %r5, %r22, %r23, %r24;
sub.s32 %r25, %r1, %r21;
mov.u32 %r26, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r27, %r6, %r20;
mad.lo.s32 %r7, %r25, %r26, %r27;
setp.lt.u32 %p4, %r5, 201;
setp.lt.u32 %p5, %r7, 201;
and.pred %p1, %p5, %p4;
mad.lo.s32 %r28, %r6, %r2, %r4;
shl.b32 %r29, %r28, 2;
mov.u32 %r30, shmem;
add.s32 %r8, %r30, %r29;
shl.b32 %r31, %r3, 2;
add.s32 %r9, %r8, %r31;
@%p1 bra $L__BB1_2;
bra.uni $L__BB1_1;

$L__BB1_2:
cvta.to.global.u64 %rd5, %rd1;
mad.lo.s32 %r33, %r7, 201, %r5;
mul.wide.s32 %rd6, %r33, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r8], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r9], %f17;
bra.uni $L__BB1_3;

$L__BB1_1:
mov.u32 %r32, 0;
st.shared.u32 [%r8], %r32;
st.shared.u32 [%r9], %r32;

$L__BB1_3:
bar.sync 0;
setp.lt.s32 %p6, %r20, 1;
@%p6 bra $L__BB1_29;

add.s32 %r36, %r5, -1;
setp.gt.u32 %p7, %r36, 198;
add.s32 %r37, %r7, -1;
setp.gt.u32 %p8, %r37, 198;
or.pred %p2, %p8, %p7;
add.s32 %r38, %r28, %r3;
shl.b32 %r39, %r38, 2;
add.s32 %r10, %r30, %r39;
cvt.rn.f32.s32 %f1, %r7;
setp.ne.s32 %p9, %r7, 100;
setp.ne.s32 %p10, %r5, 33;
or.pred %p3, %p9, %p10;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r43, %r3, %r2;
shl.b32 %r44, %r43, 2;
add.s32 %r11, %r8, %r44;
shl.b32 %r45, %r2, 2;
add.s32 %r12, %r10, %r45;
and.b32 %r13, %r20, 1;
setp.eq.s32 %p11, %r20, 1;
mov.u32 %r66, 0;
@%p11 bra $L__BB1_21;

sub.s32 %r65, %r20, %r13;
mov.u32 %r66, 0;

$L__BB1_6:
not.b32 %r47, %r66;
add.s32 %r48, %r2, %r47;
setp.ge.u32 %p12, %r4, %r48;
setp.le.s32 %p13, %r4, %r66;
or.pred %p14, %p13, %p12;
setp.le.s32 %p15, %r6, %r66;
or.pred %p16, %p15, %p14;
add.s32 %r49, %r1, %r47;
setp.ge.u32 %p17, %r6, %r49;
or.pred %p18, %p17, %p16;
or.pred %p19, %p2, %p18;
mov.f32 %f145, 0f00000000;
mov.f32 %f144, %f145;
@%p19 bra $L__BB1_13;

setp.ne.s32 %p20, %r5, 133;
mov.f32 %f19, 0f43480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p20 bra $L__BB1_9;

setp.ltu.ftz.f32 %p21, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p22, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p23, %f3, 0f3F08F5B2;
or.pred %p24, %p22, %p23;
setp.gtu.ftz.f32 %p25, %f3, 0f3EEE149C;
or.pred %p26, %p25, %p21;
and.pred %p27, %p24, %p26;
selp.u16 %rs7, 1, 0, %p27;

$L__BB1_9:
setp.ne.s16 %p28, %rs7, 0;
mov.f32 %f144, %f145;
@%p28 bra $L__BB1_13;

@%p3 bra $L__BB1_12;
bra.uni $L__BB1_11;

$L__BB1_12:
mov.f32 %f25, 0f43480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r10];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r8];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r10+4];
ld.shared.f32 %f52, [%r10+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r11];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r12];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f144, %f57, 0f3D800000, %f50;
bra.uni $L__BB1_13;

$L__BB1_11:
add.s32 %r50, %r66, 1;
cvt.rn.f32.s32 %f21, %r50;
fma.rn.ftz.f32 %f22, %f21, 0f3AA3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f144, %f24, 0f41200000;

$L__BB1_13:
bar.sync 0;
ld.shared.f32 %f59, [%r10];
st.shared.f32 [%r8], %f59;
st.shared.f32 [%r10], %f144;
bar.sync 0;
add.s32 %r51, %r66, 1;
setp.le.s32 %p29, %r4, %r51;
mov.u32 %r52, -2;
sub.s32 %r53, %r52, %r66;
add.s32 %r54, %r2, %r53;
setp.ge.u32 %p30, %r4, %r54;
or.pred %p31, %p29, %p30;
setp.le.s32 %p32, %r6, %r51;
or.pred %p33, %p32, %p31;
add.s32 %r55, %r1, %r53;
setp.ge.u32 %p34, %r6, %r55;
or.pred %p35, %p34, %p33;
or.pred %p36, %p2, %p35;
@%p36 bra $L__BB1_20;

setp.ne.s32 %p37, %r5, 133;
mov.f32 %f60, 0f43480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p37 bra $L__BB1_16;

setp.ltu.ftz.f32 %p38, %f7, 0f3EDEB830;
setp.gtu.ftz.f32 %p39, %f7, 0f3F10A3E8;
setp.ltu.ftz.f32 %p40, %f7, 0f3F08F5B2;
or.pred %p41, %p39, %p40;
setp.gtu.ftz.f32 %p42, %f7, 0f3EEE149C;
or.pred %p43, %p42, %p38;
and.pred %p44, %p41, %p43;
selp.u16 %rs8, 1, 0, %p44;

$L__BB1_16:
setp.ne.s16 %p45, %rs8, 0;
@%p45 bra $L__BB1_20;

@%p3 bra $L__BB1_19;
bra.uni $L__BB1_18;

$L__BB1_19:
mov.f32 %f66, 0f43480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r10];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r8];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r10+4];
ld.shared.f32 %f93, [%r10+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r11];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r12];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f145, %f98, 0f3D800000, %f91;
bra.uni $L__BB1_20;

$L__BB1_18:
add.s32 %r56, %r66, 2;
cvt.rn.f32.s32 %f62, %r56;
fma.rn.ftz.f32 %f63, %f62, 0f3AA3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f145, %f65, 0f41200000;

$L__BB1_20:
bar.sync 0;
ld.shared.f32 %f99, [%r10];
st.shared.f32 [%r8], %f99;
st.shared.f32 [%r10], %f145;
bar.sync 0;
add.s32 %r66, %r66, 2;
add.s32 %r65, %r65, -2;
setp.ne.s32 %p46, %r65, 0;
@%p46 bra $L__BB1_6;

$L__BB1_21:
setp.eq.s32 %p47, %r13, 0;
mov.f32 %f146, 0f00000000;
@%p47 bra $L__BB1_29;

setp.le.s32 %p48, %r4, %r66;
not.b32 %r57, %r66;
add.s32 %r58, %r2, %r57;
setp.ge.u32 %p49, %r4, %r58;
or.pred %p50, %p48, %p49;
setp.le.s32 %p51, %r6, %r66;
or.pred %p52, %p51, %p50;
add.s32 %r59, %r1, %r57;
setp.ge.u32 %p53, %r6, %r59;
or.pred %p54, %p53, %p52;
or.pred %p55, %p2, %p54;
@%p55 bra $L__BB1_28;

setp.ne.s32 %p56, %r5, 133;
mov.f32 %f101, 0f43480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p56 bra $L__BB1_25;

setp.ltu.ftz.f32 %p57, %f11, 0f3EDEB830;
setp.gtu.ftz.f32 %p58, %f11, 0f3F10A3E8;
setp.ltu.ftz.f32 %p59, %f11, 0f3F08F5B2;
or.pred %p60, %p58, %p59;
setp.gtu.ftz.f32 %p61, %f11, 0f3EEE149C;
or.pred %p62, %p61, %p57;
and.pred %p63, %p60, %p62;
@%p63 bra $L__BB1_28;

$L__BB1_25:
@%p3 bra $L__BB1_27;
bra.uni $L__BB1_26;

$L__BB1_27:
mov.f32 %f107, 0f43480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r10];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r8];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r10+4];
ld.shared.f32 %f134, [%r10+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r11];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r12];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f146, %f139, 0f3D800000, %f132;
bra.uni $L__BB1_28;

$L__BB1_26:
add.s32 %r60, %r66, 1;
cvt.rn.f32.s32 %f103, %r60;
fma.rn.ftz.f32 %f104, %f103, 0f3AA3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f146, %f106, 0f41200000;

$L__BB1_28:
bar.sync 0;
ld.shared.f32 %f140, [%r10];
st.shared.f32 [%r8], %f140;
st.shared.f32 [%r10], %f146;
bar.sync 0;

$L__BB1_29:
setp.ge.s32 %p64, %r4, %r20;
sub.s32 %r61, %r2, %r20;
setp.lt.u32 %p65, %r4, %r61;
and.pred %p66, %p64, %p65;
setp.ge.s32 %p67, %r6, %r20;
and.pred %p68, %p67, %p66;
sub.s32 %r62, %r1, %r20;
setp.lt.u32 %p69, %r6, %r62;
and.pred %p70, %p69, %p68;
and.pred %p71, %p70, %p1;
not.pred %p72, %p71;
@%p72 bra $L__BB1_31;

mad.lo.s32 %r63, %r7, 201, %r5;
ld.shared.f32 %f141, [%r8];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r63, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r9];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB1_31:
bar.sync 0;
ret;

}
//
.visible .entry _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 3200;
@%p1 bra $L__BB2_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB2_2:
setp.gt.s32 %p2, %r2, 3200;
@%p2 bra $L__BB2_12;

mul.lo.s32 %r8, %r19, 3201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB2_4:
setp.eq.s32 %p3, %r20, 3200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 3200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB2_11;

mov.f32 %f9, 0f45480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 2133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB2_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5C3;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE147A;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB2_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB2_11;

setp.ne.s32 %p19, %r19, 1600;
setp.ne.s32 %p20, %r20, 533;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB2_10;
bra.uni $L__BB2_9;

$L__BB2_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f45480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-12804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+12804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB2_11;

$L__BB2_9:
mov.f32 %f46, %f4;

$L__BB2_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 3201;
@%p22 bra $L__BB2_4;

$L__BB2_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 3201;
@%p23 bra $L__BB2_2;

$L__BB2_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<73>;
.reg .b16 %rs<9>;
.reg .f32 %f<147>;
.reg .b32 %r<67>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r20, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r21, %r20, 1;
sub.s32 %r22, %r2, %r21;
mov.u32 %r23, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r24, %r4, %r20;
mad.lo.s32 %r5, %r22, %r23, %r24;
sub.s32 %r25, %r1, %r21;
mov.u32 %r26, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r27, %r6, %r20;
mad.lo.s32 %r7, %r25, %r26, %r27;
setp.lt.u32 %p4, %r5, 3201;
setp.lt.u32 %p5, %r7, 3201;
and.pred %p1, %p5, %p4;
mad.lo.s32 %r28, %r6, %r2, %r4;
shl.b32 %r29, %r28, 2;
mov.u32 %r30, shmem;
add.s32 %r8, %r30, %r29;
shl.b32 %r31, %r3, 2;
add.s32 %r9, %r8, %r31;
@%p1 bra $L__BB3_2;
bra.uni $L__BB3_1;

$L__BB3_2:
cvta.to.global.u64 %rd5, %rd1;
mad.lo.s32 %r33, %r7, 3201, %r5;
mul.wide.s32 %rd6, %r33, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r8], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r9], %f17;
bra.uni $L__BB3_3;

$L__BB3_1:
mov.u32 %r32, 0;
st.shared.u32 [%r8], %r32;
st.shared.u32 [%r9], %r32;

$L__BB3_3:
bar.sync 0;
setp.lt.s32 %p6, %r20, 1;
@%p6 bra $L__BB3_29;

add.s32 %r36, %r5, -1;
setp.gt.u32 %p7, %r36, 3198;
add.s32 %r37, %r7, -1;
setp.gt.u32 %p8, %r37, 3198;
or.pred %p2, %p8, %p7;
add.s32 %r38, %r28, %r3;
shl.b32 %r39, %r38, 2;
add.s32 %r10, %r30, %r39;
cvt.rn.f32.s32 %f1, %r7;
setp.ne.s32 %p9, %r7, 1600;
setp.ne.s32 %p10, %r5, 533;
or.pred %p3, %p9, %p10;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r43, %r3, %r2;
shl.b32 %r44, %r43, 2;
add.s32 %r11, %r8, %r44;
shl.b32 %r45, %r2, 2;
add.s32 %r12, %r10, %r45;
and.b32 %r13, %r20, 1;
setp.eq.s32 %p11, %r20, 1;
mov.u32 %r66, 0;
@%p11 bra $L__BB3_21;

sub.s32 %r65, %r20, %r13;
mov.u32 %r66, 0;

$L__BB3_6:
not.b32 %r47, %r66;
add.s32 %r48, %r2, %r47;
setp.ge.u32 %p12, %r4, %r48;
setp.le.s32 %p13, %r4, %r66;
or.pred %p14, %p13, %p12;
setp.le.s32 %p15, %r6, %r66;
or.pred %p16, %p15, %p14;
add.s32 %r49, %r1, %r47;
setp.ge.u32 %p17, %r6, %r49;
or.pred %p18, %p17, %p16;
or.pred %p19, %p2, %p18;
mov.f32 %f145, 0f00000000;
mov.f32 %f144, %f145;
@%p19 bra $L__BB3_13;

setp.ne.s32 %p20, %r5, 2133;
mov.f32 %f19, 0f45480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p20 bra $L__BB3_9;

setp.ltu.ftz.f32 %p21, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p22, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p23, %f3, 0f3F08F5C3;
or.pred %p24, %p22, %p23;
setp.gtu.ftz.f32 %p25, %f3, 0f3EEE147A;
or.pred %p26, %p25, %p21;
and.pred %p27, %p24, %p26;
selp.u16 %rs7, 1, 0, %p27;

$L__BB3_9:
setp.ne.s16 %p28, %rs7, 0;
mov.f32 %f144, %f145;
@%p28 bra $L__BB3_13;

@%p3 bra $L__BB3_12;
bra.uni $L__BB3_11;

$L__BB3_12:
mov.f32 %f25, 0f45480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r10];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r8];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r10+4];
ld.shared.f32 %f52, [%r10+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r11];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r12];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f144, %f57, 0f3D800000, %f50;
bra.uni $L__BB3_13;

$L__BB3_11:
add.s32 %r50, %r66, 1;
cvt.rn.f32.s32 %f21, %r50;
fma.rn.ftz.f32 %f22, %f21, 0f38A3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f144, %f24, 0f41200000;

$L__BB3_13:
bar.sync 0;
ld.shared.f32 %f59, [%r10];
st.shared.f32 [%r8], %f59;
st.shared.f32 [%r10], %f144;
bar.sync 0;
add.s32 %r51, %r66, 1;
setp.le.s32 %p29, %r4, %r51;
mov.u32 %r52, -2;
sub.s32 %r53, %r52, %r66;
add.s32 %r54, %r2, %r53;
setp.ge.u32 %p30, %r4, %r54;
or.pred %p31, %p29, %p30;
setp.le.s32 %p32, %r6, %r51;
or.pred %p33, %p32, %p31;
add.s32 %r55, %r1, %r53;
setp.ge.u32 %p34, %r6, %r55;
or.pred %p35, %p34, %p33;
or.pred %p36, %p2, %p35;
@%p36 bra $L__BB3_20;

setp.ne.s32 %p37, %r5, 2133;
mov.f32 %f60, 0f45480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p37 bra $L__BB3_16;

setp.ltu.ftz.f32 %p38, %f7, 0f3EDEB852;
setp.gtu.ftz.f32 %p39, %f7, 0f3F10A3D7;
setp.ltu.ftz.f32 %p40, %f7, 0f3F08F5C3;
or.pred %p41, %p39, %p40;
setp.gtu.ftz.f32 %p42, %f7, 0f3EEE147A;
or.pred %p43, %p42, %p38;
and.pred %p44, %p41, %p43;
selp.u16 %rs8, 1, 0, %p44;

$L__BB3_16:
setp.ne.s16 %p45, %rs8, 0;
@%p45 bra $L__BB3_20;

@%p3 bra $L__BB3_19;
bra.uni $L__BB3_18;

$L__BB3_19:
mov.f32 %f66, 0f45480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r10];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r8];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r10+4];
ld.shared.f32 %f93, [%r10+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r11];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r12];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f145, %f98, 0f3D800000, %f91;
bra.uni $L__BB3_20;

$L__BB3_18:
add.s32 %r56, %r66, 2;
cvt.rn.f32.s32 %f62, %r56;
fma.rn.ftz.f32 %f63, %f62, 0f38A3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f145, %f65, 0f41200000;

$L__BB3_20:
bar.sync 0;
ld.shared.f32 %f99, [%r10];
st.shared.f32 [%r8], %f99;
st.shared.f32 [%r10], %f145;
bar.sync 0;
add.s32 %r66, %r66, 2;
add.s32 %r65, %r65, -2;
setp.ne.s32 %p46, %r65, 0;
@%p46 bra $L__BB3_6;

$L__BB3_21:
setp.eq.s32 %p47, %r13, 0;
mov.f32 %f146, 0f00000000;
@%p47 bra $L__BB3_29;

setp.le.s32 %p48, %r4, %r66;
not.b32 %r57, %r66;
add.s32 %r58, %r2, %r57;
setp.ge.u32 %p49, %r4, %r58;
or.pred %p50, %p48, %p49;
setp.le.s32 %p51, %r6, %r66;
or.pred %p52, %p51, %p50;
add.s32 %r59, %r1, %r57;
setp.ge.u32 %p53, %r6, %r59;
or.pred %p54, %p53, %p52;
or.pred %p55, %p2, %p54;
@%p55 bra $L__BB3_28;

setp.ne.s32 %p56, %r5, 2133;
mov.f32 %f101, 0f45480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p56 bra $L__BB3_25;

setp.ltu.ftz.f32 %p57, %f11, 0f3EDEB852;
setp.gtu.ftz.f32 %p58, %f11, 0f3F10A3D7;
setp.ltu.ftz.f32 %p59, %f11, 0f3F08F5C3;
or.pred %p60, %p58, %p59;
setp.gtu.ftz.f32 %p61, %f11, 0f3EEE147A;
or.pred %p62, %p61, %p57;
and.pred %p63, %p60, %p62;
@%p63 bra $L__BB3_28;

$L__BB3_25:
@%p3 bra $L__BB3_27;
bra.uni $L__BB3_26;

$L__BB3_27:
mov.f32 %f107, 0f45480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r10];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r8];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r10+4];
ld.shared.f32 %f134, [%r10+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r11];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r12];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f146, %f139, 0f3D800000, %f132;
bra.uni $L__BB3_28;

$L__BB3_26:
add.s32 %r60, %r66, 1;
cvt.rn.f32.s32 %f103, %r60;
fma.rn.ftz.f32 %f104, %f103, 0f38A3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f146, %f106, 0f41200000;

$L__BB3_28:
bar.sync 0;
ld.shared.f32 %f140, [%r10];
st.shared.f32 [%r8], %f140;
st.shared.f32 [%r10], %f146;
bar.sync 0;

$L__BB3_29:
setp.ge.s32 %p64, %r4, %r20;
sub.s32 %r61, %r2, %r20;
setp.lt.u32 %p65, %r4, %r61;
and.pred %p66, %p64, %p65;
setp.ge.s32 %p67, %r6, %r20;
and.pred %p68, %p67, %p66;
sub.s32 %r62, %r1, %r20;
setp.lt.u32 %p69, %r6, %r62;
and.pred %p70, %p69, %p68;
and.pred %p71, %p70, %p1;
not.pred %p72, %p71;
@%p72 bra $L__BB3_31;

mad.lo.s32 %r63, %r7, 3201, %r5;
ld.shared.f32 %f141, [%r8];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r63, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r9];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB3_31:
bar.sync 0;
ret;

}


