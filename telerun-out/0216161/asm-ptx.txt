
Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_89
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = 

//
//
//
//
//
//

.version 8.7
.target sm_89
.address_size 64

//
.extern .shared .align 16 .b8 shmem[];

.visible .entry _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 200;
@%p1 bra $L__BB0_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB0_2:
setp.gt.s32 %p2, %r2, 200;
@%p2 bra $L__BB0_12;

mul.lo.s32 %r8, %r19, 201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB0_4:
setp.eq.s32 %p3, %r20, 200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB0_11;

mov.f32 %f9, 0f43480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB0_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5B2;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE149C;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB0_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB0_11;

setp.ne.s32 %p19, %r19, 100;
setp.ne.s32 %p20, %r20, 33;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB0_10;
bra.uni $L__BB0_9;

$L__BB0_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f43480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB0_11;

$L__BB0_9:
mov.f32 %f46, %f4;

$L__BB0_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 201;
@%p22 bra $L__BB0_4;

$L__BB0_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 201;
@%p23 bra $L__BB0_2;

$L__BB0_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<101>;
.reg .b16 %rs<9>;
.reg .f32 %f<146>;
.reg .b32 %r<60>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r23, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r24, %r23, 1;
sub.s32 %r25, %r2, %r24;
mov.u32 %r26, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r27, %r4, %r23;
mad.lo.s32 %r5, %r25, %r26, %r27;
sub.s32 %r28, %r1, %r24;
mov.u32 %r29, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r30, %r6, %r23;
mad.lo.s32 %r7, %r28, %r29, %r30;
mad.lo.s32 %r8, %r7, 201, %r5;
mad.lo.s32 %r9, %r6, %r2, %r4;
setp.lt.u32 %p10, %r5, 201;
setp.lt.u32 %p11, %r7, 201;
and.pred %p1, %p11, %p10;
shl.b32 %r31, %r9, 2;
mov.u32 %r32, shmem;
add.s32 %r10, %r32, %r31;
shl.b32 %r33, %r3, 2;
add.s32 %r11, %r10, %r33;
@%p1 bra $L__BB1_2;
bra.uni $L__BB1_1;

$L__BB1_2:
cvta.to.global.u64 %rd5, %rd1;
mul.wide.s32 %rd6, %r8, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r10], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r11], %f17;
bra.uni $L__BB1_3;

$L__BB1_1:
mov.u32 %r34, 0;
st.shared.u32 [%r10], %r34;
st.shared.u32 [%r11], %r34;

$L__BB1_3:
bar.sync 0;
setp.lt.s32 %p12, %r23, 1;
@%p12 bra $L__BB1_44;

setp.eq.s32 %p2, %r7, 0;
mov.u32 %r59, 0;
cvt.rn.f32.s32 %f1, %r7;
add.s32 %r36, %r9, %r3;
shl.b32 %r37, %r36, 2;
add.s32 %r12, %r32, %r37;
setp.ne.s32 %p13, %r7, 100;
setp.ne.s32 %p14, %r5, 33;
or.pred %p3, %p13, %p14;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r39, %r3, %r2;
shl.b32 %r42, %r39, 2;
add.s32 %r13, %r10, %r42;
shl.b32 %r43, %r2, 2;
add.s32 %r14, %r12, %r43;
and.b32 %r15, %r23, 1;
setp.eq.s32 %p15, %r23, 1;
@%p15 bra $L__BB1_31;

sub.s32 %r58, %r23, %r15;
mov.u32 %r59, 0;

$L__BB1_6:
mov.pred %p98, -1;
setp.eq.s32 %p17, %r5, 0;
@%p17 bra $L__BB1_9;

setp.eq.s32 %p18, %r5, 200;
@%p18 bra $L__BB1_9;

mov.pred %p98, %p2;

$L__BB1_9:
not.b32 %r45, %r59;
setp.eq.s32 %p19, %r7, 200;
or.pred %p20, %p19, %p98;
add.s32 %r46, %r1, %r45;
setp.lt.u32 %p21, %r6, %r46;
setp.gt.s32 %p22, %r6, %r59;
setp.gt.s32 %p23, %r4, %r59;
add.s32 %r47, %r2, %r45;
setp.lt.u32 %p24, %r4, %r47;
and.pred %p25, %p23, %p24;
and.pred %p26, %p22, %p25;
and.pred %p27, %p21, %p26;
and.pred %p5, %p1, %p27;
not.pred %p28, %p5;
or.pred %p29, %p20, %p28;
mov.f32 %f143, 0f00000000;
@%p29 bra $L__BB1_16;

setp.ne.s32 %p30, %r5, 133;
mov.f32 %f19, 0f43480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p30 bra $L__BB1_12;

setp.ltu.ftz.f32 %p31, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p32, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p33, %f3, 0f3F08F5B2;
or.pred %p34, %p32, %p33;
setp.gtu.ftz.f32 %p35, %f3, 0f3EEE149C;
or.pred %p36, %p35, %p31;
and.pred %p37, %p34, %p36;
selp.u16 %rs7, 1, 0, %p37;

$L__BB1_12:
setp.ne.s16 %p38, %rs7, 0;
@%p38 bra $L__BB1_16;

@%p3 bra $L__BB1_15;
bra.uni $L__BB1_14;

$L__BB1_15:
mov.f32 %f25, 0f43480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r12];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r10];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r12+4];
ld.shared.f32 %f52, [%r12+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r13];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r14];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f143, %f57, 0f3D800000, %f50;
bra.uni $L__BB1_16;

$L__BB1_14:
cvt.rn.f32.s32 %f21, %r59;
fma.rn.ftz.f32 %f22, %f21, 0f3AA3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f143, %f24, 0f41200000;

$L__BB1_16:
bar.sync 0;
@%p28 bra $L__BB1_18;

ld.shared.f32 %f58, [%r12];
st.shared.f32 [%r10], %f58;
st.shared.f32 [%r12], %f143;

$L__BB1_18:
bar.sync 0;
add.s32 %r19, %r59, 1;
mov.pred %p99, -1;
@%p17 bra $L__BB1_21;

setp.eq.s32 %p42, %r5, 200;
@%p42 bra $L__BB1_21;

mov.pred %p99, %p2;

$L__BB1_21:
mov.u32 %r48, -2;
sub.s32 %r49, %r48, %r59;
or.pred %p44, %p19, %p99;
add.s32 %r50, %r1, %r49;
setp.lt.u32 %p45, %r6, %r50;
setp.gt.s32 %p46, %r6, %r19;
add.s32 %r51, %r2, %r49;
setp.lt.u32 %p47, %r4, %r51;
setp.gt.s32 %p48, %r4, %r19;
and.pred %p49, %p48, %p47;
and.pred %p50, %p46, %p49;
and.pred %p51, %p45, %p50;
and.pred %p7, %p1, %p51;
not.pred %p52, %p7;
or.pred %p53, %p44, %p52;
mov.f32 %f144, 0f00000000;
@%p53 bra $L__BB1_28;

setp.ne.s32 %p54, %r5, 133;
mov.f32 %f60, 0f43480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p54 bra $L__BB1_24;

setp.ltu.ftz.f32 %p55, %f7, 0f3EDEB830;
setp.gtu.ftz.f32 %p56, %f7, 0f3F10A3E8;
setp.ltu.ftz.f32 %p57, %f7, 0f3F08F5B2;
or.pred %p58, %p56, %p57;
setp.gtu.ftz.f32 %p59, %f7, 0f3EEE149C;
or.pred %p60, %p59, %p55;
and.pred %p61, %p58, %p60;
selp.u16 %rs8, 1, 0, %p61;

$L__BB1_24:
setp.ne.s16 %p62, %rs8, 0;
@%p62 bra $L__BB1_28;

@%p3 bra $L__BB1_27;
bra.uni $L__BB1_26;

$L__BB1_27:
mov.f32 %f66, 0f43480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r12];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r10];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r12+4];
ld.shared.f32 %f93, [%r12+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r13];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r14];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f144, %f98, 0f3D800000, %f91;
bra.uni $L__BB1_28;

$L__BB1_26:
cvt.rn.f32.s32 %f62, %r19;
fma.rn.ftz.f32 %f63, %f62, 0f3AA3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f144, %f65, 0f41200000;

$L__BB1_28:
bar.sync 0;
@%p52 bra $L__BB1_30;

ld.shared.f32 %f99, [%r12];
st.shared.f32 [%r10], %f99;
st.shared.f32 [%r12], %f144;

$L__BB1_30:
bar.sync 0;
add.s32 %r59, %r59, 2;
add.s32 %r58, %r58, -2;
setp.ne.s32 %p64, %r58, 0;
@%p64 bra $L__BB1_6;

$L__BB1_31:
setp.eq.s32 %p65, %r15, 0;
@%p65 bra $L__BB1_44;

mov.pred %p100, -1;
setp.eq.s32 %p67, %r5, 0;
@%p67 bra $L__BB1_35;

setp.eq.s32 %p68, %r5, 200;
@%p68 bra $L__BB1_35;

mov.pred %p100, %p2;

$L__BB1_35:
not.b32 %r52, %r59;
setp.eq.s32 %p69, %r7, 200;
or.pred %p70, %p69, %p100;
add.s32 %r53, %r1, %r52;
setp.lt.u32 %p71, %r6, %r53;
setp.gt.s32 %p72, %r6, %r59;
add.s32 %r54, %r2, %r52;
setp.lt.u32 %p73, %r4, %r54;
setp.gt.s32 %p74, %r4, %r59;
and.pred %p75, %p74, %p73;
and.pred %p76, %p72, %p75;
and.pred %p77, %p71, %p76;
and.pred %p9, %p1, %p77;
not.pred %p78, %p9;
or.pred %p79, %p70, %p78;
mov.f32 %f145, 0f00000000;
@%p79 bra $L__BB1_41;

setp.ne.s32 %p80, %r5, 133;
mov.f32 %f101, 0f43480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p80 bra $L__BB1_38;

setp.ltu.ftz.f32 %p81, %f11, 0f3EDEB830;
setp.gtu.ftz.f32 %p82, %f11, 0f3F10A3E8;
setp.ltu.ftz.f32 %p83, %f11, 0f3F08F5B2;
or.pred %p84, %p82, %p83;
setp.gtu.ftz.f32 %p85, %f11, 0f3EEE149C;
or.pred %p86, %p85, %p81;
and.pred %p87, %p84, %p86;
@%p87 bra $L__BB1_41;

$L__BB1_38:
@%p3 bra $L__BB1_40;
bra.uni $L__BB1_39;

$L__BB1_40:
mov.f32 %f107, 0f43480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r12];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r10];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r12+4];
ld.shared.f32 %f134, [%r12+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r13];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r14];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f145, %f139, 0f3D800000, %f132;
bra.uni $L__BB1_41;

$L__BB1_39:
cvt.rn.f32.s32 %f103, %r59;
fma.rn.ftz.f32 %f104, %f103, 0f3AA3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f145, %f106, 0f41200000;

$L__BB1_41:
bar.sync 0;
@%p78 bra $L__BB1_43;

ld.shared.f32 %f140, [%r12];
st.shared.f32 [%r10], %f140;
st.shared.f32 [%r12], %f145;

$L__BB1_43:
bar.sync 0;

$L__BB1_44:
setp.ge.s32 %p89, %r4, %r23;
sub.s32 %r55, %r2, %r23;
setp.lt.u32 %p90, %r4, %r55;
and.pred %p91, %p89, %p90;
setp.ge.s32 %p92, %r6, %r23;
and.pred %p93, %p92, %p91;
sub.s32 %r56, %r1, %r23;
setp.lt.u32 %p94, %r6, %r56;
and.pred %p95, %p94, %p93;
and.pred %p96, %p95, %p1;
not.pred %p97, %p96;
@%p97 bra $L__BB1_46;

ld.shared.f32 %f141, [%r10];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r8, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r11];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB1_46:
bar.sync 0;
ret;

}
//
.visible .entry _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 3200;
@%p1 bra $L__BB2_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB2_2:
setp.gt.s32 %p2, %r2, 3200;
@%p2 bra $L__BB2_12;

mul.lo.s32 %r8, %r19, 3201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB2_4:
setp.eq.s32 %p3, %r20, 3200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 3200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB2_11;

mov.f32 %f9, 0f45480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 2133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB2_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5C3;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE147A;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB2_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB2_11;

setp.ne.s32 %p19, %r19, 1600;
setp.ne.s32 %p20, %r20, 533;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB2_10;
bra.uni $L__BB2_9;

$L__BB2_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f45480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-12804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+12804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB2_11;

$L__BB2_9:
mov.f32 %f46, %f4;

$L__BB2_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 3201;
@%p22 bra $L__BB2_4;

$L__BB2_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 3201;
@%p23 bra $L__BB2_2;

$L__BB2_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<101>;
.reg .b16 %rs<9>;
.reg .f32 %f<146>;
.reg .b32 %r<60>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r23, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r24, %r23, 1;
sub.s32 %r25, %r2, %r24;
mov.u32 %r26, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r27, %r4, %r23;
mad.lo.s32 %r5, %r25, %r26, %r27;
sub.s32 %r28, %r1, %r24;
mov.u32 %r29, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r30, %r6, %r23;
mad.lo.s32 %r7, %r28, %r29, %r30;
mad.lo.s32 %r8, %r7, 3201, %r5;
mad.lo.s32 %r9, %r6, %r2, %r4;
setp.lt.u32 %p10, %r5, 3201;
setp.lt.u32 %p11, %r7, 3201;
and.pred %p1, %p11, %p10;
shl.b32 %r31, %r9, 2;
mov.u32 %r32, shmem;
add.s32 %r10, %r32, %r31;
shl.b32 %r33, %r3, 2;
add.s32 %r11, %r10, %r33;
@%p1 bra $L__BB3_2;
bra.uni $L__BB3_1;

$L__BB3_2:
cvta.to.global.u64 %rd5, %rd1;
mul.wide.s32 %rd6, %r8, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r10], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r11], %f17;
bra.uni $L__BB3_3;

$L__BB3_1:
mov.u32 %r34, 0;
st.shared.u32 [%r10], %r34;
st.shared.u32 [%r11], %r34;

$L__BB3_3:
bar.sync 0;
setp.lt.s32 %p12, %r23, 1;
@%p12 bra $L__BB3_44;

setp.eq.s32 %p2, %r7, 0;
mov.u32 %r59, 0;
cvt.rn.f32.s32 %f1, %r7;
add.s32 %r36, %r9, %r3;
shl.b32 %r37, %r36, 2;
add.s32 %r12, %r32, %r37;
setp.ne.s32 %p13, %r7, 1600;
setp.ne.s32 %p14, %r5, 533;
or.pred %p3, %p13, %p14;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r39, %r3, %r2;
shl.b32 %r42, %r39, 2;
add.s32 %r13, %r10, %r42;
shl.b32 %r43, %r2, 2;
add.s32 %r14, %r12, %r43;
and.b32 %r15, %r23, 1;
setp.eq.s32 %p15, %r23, 1;
@%p15 bra $L__BB3_31;

sub.s32 %r58, %r23, %r15;
mov.u32 %r59, 0;

$L__BB3_6:
mov.pred %p98, -1;
setp.eq.s32 %p17, %r5, 0;
@%p17 bra $L__BB3_9;

setp.eq.s32 %p18, %r5, 3200;
@%p18 bra $L__BB3_9;

mov.pred %p98, %p2;

$L__BB3_9:
not.b32 %r45, %r59;
setp.eq.s32 %p19, %r7, 3200;
or.pred %p20, %p19, %p98;
add.s32 %r46, %r1, %r45;
setp.lt.u32 %p21, %r6, %r46;
setp.gt.s32 %p22, %r6, %r59;
setp.gt.s32 %p23, %r4, %r59;
add.s32 %r47, %r2, %r45;
setp.lt.u32 %p24, %r4, %r47;
and.pred %p25, %p23, %p24;
and.pred %p26, %p22, %p25;
and.pred %p27, %p21, %p26;
and.pred %p5, %p1, %p27;
not.pred %p28, %p5;
or.pred %p29, %p20, %p28;
mov.f32 %f143, 0f00000000;
@%p29 bra $L__BB3_16;

setp.ne.s32 %p30, %r5, 2133;
mov.f32 %f19, 0f45480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p30 bra $L__BB3_12;

setp.ltu.ftz.f32 %p31, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p32, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p33, %f3, 0f3F08F5C3;
or.pred %p34, %p32, %p33;
setp.gtu.ftz.f32 %p35, %f3, 0f3EEE147A;
or.pred %p36, %p35, %p31;
and.pred %p37, %p34, %p36;
selp.u16 %rs7, 1, 0, %p37;

$L__BB3_12:
setp.ne.s16 %p38, %rs7, 0;
@%p38 bra $L__BB3_16;

@%p3 bra $L__BB3_15;
bra.uni $L__BB3_14;

$L__BB3_15:
mov.f32 %f25, 0f45480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r12];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r10];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r12+4];
ld.shared.f32 %f52, [%r12+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r13];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r14];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f143, %f57, 0f3D800000, %f50;
bra.uni $L__BB3_16;

$L__BB3_14:
cvt.rn.f32.s32 %f21, %r59;
fma.rn.ftz.f32 %f22, %f21, 0f38A3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f143, %f24, 0f41200000;

$L__BB3_16:
bar.sync 0;
@%p28 bra $L__BB3_18;

ld.shared.f32 %f58, [%r12];
st.shared.f32 [%r10], %f58;
st.shared.f32 [%r12], %f143;

$L__BB3_18:
bar.sync 0;
add.s32 %r19, %r59, 1;
mov.pred %p99, -1;
@%p17 bra $L__BB3_21;

setp.eq.s32 %p42, %r5, 3200;
@%p42 bra $L__BB3_21;

mov.pred %p99, %p2;

$L__BB3_21:
mov.u32 %r48, -2;
sub.s32 %r49, %r48, %r59;
or.pred %p44, %p19, %p99;
add.s32 %r50, %r1, %r49;
setp.lt.u32 %p45, %r6, %r50;
setp.gt.s32 %p46, %r6, %r19;
add.s32 %r51, %r2, %r49;
setp.lt.u32 %p47, %r4, %r51;
setp.gt.s32 %p48, %r4, %r19;
and.pred %p49, %p48, %p47;
and.pred %p50, %p46, %p49;
and.pred %p51, %p45, %p50;
and.pred %p7, %p1, %p51;
not.pred %p52, %p7;
or.pred %p53, %p44, %p52;
mov.f32 %f144, 0f00000000;
@%p53 bra $L__BB3_28;

setp.ne.s32 %p54, %r5, 2133;
mov.f32 %f60, 0f45480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p54 bra $L__BB3_24;

setp.ltu.ftz.f32 %p55, %f7, 0f3EDEB852;
setp.gtu.ftz.f32 %p56, %f7, 0f3F10A3D7;
setp.ltu.ftz.f32 %p57, %f7, 0f3F08F5C3;
or.pred %p58, %p56, %p57;
setp.gtu.ftz.f32 %p59, %f7, 0f3EEE147A;
or.pred %p60, %p59, %p55;
and.pred %p61, %p58, %p60;
selp.u16 %rs8, 1, 0, %p61;

$L__BB3_24:
setp.ne.s16 %p62, %rs8, 0;
@%p62 bra $L__BB3_28;

@%p3 bra $L__BB3_27;
bra.uni $L__BB3_26;

$L__BB3_27:
mov.f32 %f66, 0f45480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r12];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r10];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r12+4];
ld.shared.f32 %f93, [%r12+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r13];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r14];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f144, %f98, 0f3D800000, %f91;
bra.uni $L__BB3_28;

$L__BB3_26:
cvt.rn.f32.s32 %f62, %r19;
fma.rn.ftz.f32 %f63, %f62, 0f38A3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f144, %f65, 0f41200000;

$L__BB3_28:
bar.sync 0;
@%p52 bra $L__BB3_30;

ld.shared.f32 %f99, [%r12];
st.shared.f32 [%r10], %f99;
st.shared.f32 [%r12], %f144;

$L__BB3_30:
bar.sync 0;
add.s32 %r59, %r59, 2;
add.s32 %r58, %r58, -2;
setp.ne.s32 %p64, %r58, 0;
@%p64 bra $L__BB3_6;

$L__BB3_31:
setp.eq.s32 %p65, %r15, 0;
@%p65 bra $L__BB3_44;

mov.pred %p100, -1;
setp.eq.s32 %p67, %r5, 0;
@%p67 bra $L__BB3_35;

setp.eq.s32 %p68, %r5, 3200;
@%p68 bra $L__BB3_35;

mov.pred %p100, %p2;

$L__BB3_35:
not.b32 %r52, %r59;
setp.eq.s32 %p69, %r7, 3200;
or.pred %p70, %p69, %p100;
add.s32 %r53, %r1, %r52;
setp.lt.u32 %p71, %r6, %r53;
setp.gt.s32 %p72, %r6, %r59;
add.s32 %r54, %r2, %r52;
setp.lt.u32 %p73, %r4, %r54;
setp.gt.s32 %p74, %r4, %r59;
and.pred %p75, %p74, %p73;
and.pred %p76, %p72, %p75;
and.pred %p77, %p71, %p76;
and.pred %p9, %p1, %p77;
not.pred %p78, %p9;
or.pred %p79, %p70, %p78;
mov.f32 %f145, 0f00000000;
@%p79 bra $L__BB3_41;

setp.ne.s32 %p80, %r5, 2133;
mov.f32 %f101, 0f45480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p80 bra $L__BB3_38;

setp.ltu.ftz.f32 %p81, %f11, 0f3EDEB852;
setp.gtu.ftz.f32 %p82, %f11, 0f3F10A3D7;
setp.ltu.ftz.f32 %p83, %f11, 0f3F08F5C3;
or.pred %p84, %p82, %p83;
setp.gtu.ftz.f32 %p85, %f11, 0f3EEE147A;
or.pred %p86, %p85, %p81;
and.pred %p87, %p84, %p86;
@%p87 bra $L__BB3_41;

$L__BB3_38:
@%p3 bra $L__BB3_40;
bra.uni $L__BB3_39;

$L__BB3_40:
mov.f32 %f107, 0f45480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r12];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r10];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r12+4];
ld.shared.f32 %f134, [%r12+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r13];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r14];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f145, %f139, 0f3D800000, %f132;
bra.uni $L__BB3_41;

$L__BB3_39:
cvt.rn.f32.s32 %f103, %r59;
fma.rn.ftz.f32 %f104, %f103, 0f38A3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f145, %f106, 0f41200000;

$L__BB3_41:
bar.sync 0;
@%p78 bra $L__BB3_43;

ld.shared.f32 %f140, [%r12];
st.shared.f32 [%r10], %f140;
st.shared.f32 [%r12], %f145;

$L__BB3_43:
bar.sync 0;

$L__BB3_44:
setp.ge.s32 %p89, %r4, %r23;
sub.s32 %r55, %r2, %r23;
setp.lt.u32 %p90, %r4, %r55;
and.pred %p91, %p89, %p90;
setp.ge.s32 %p92, %r6, %r23;
and.pred %p93, %p92, %p91;
sub.s32 %r56, %r1, %r23;
setp.lt.u32 %p94, %r6, %r56;
and.pred %p95, %p94, %p93;
and.pred %p96, %p95, %p1;
not.pred %p97, %p96;
@%p97 bra $L__BB3_46;

ld.shared.f32 %f141, [%r10];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r8, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r11];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB3_46:
bar.sync 0;
ret;

}


