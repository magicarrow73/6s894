
Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin elf code:
================
arch = sm_89
code version = [1,7]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_89
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = 

//
//
//
//
//
//

.version 8.7
.target sm_89
.address_size 64

//
.extern .shared .align 16 .b8 shmem[];

.visible .entry _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI20DoubleSlitSmallScaleEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 200;
@%p1 bra $L__BB0_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB0_2:
setp.gt.s32 %p2, %r2, 200;
@%p2 bra $L__BB0_12;

mul.lo.s32 %r8, %r19, 201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB0_4:
setp.eq.s32 %p3, %r20, 200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB0_11;

mov.f32 %f9, 0f43480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB0_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5B2;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE149C;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB0_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB0_11;

setp.ne.s32 %p19, %r19, 100;
setp.ne.s32 %p20, %r20, 33;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB0_10;
bra.uni $L__BB0_9;

$L__BB0_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f43480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB0_11;

$L__BB0_9:
mov.f32 %f46, %f4;

$L__BB0_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 201;
@%p22 bra $L__BB0_4;

$L__BB0_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 201;
@%p23 bra $L__BB0_2;

$L__BB0_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<98>;
.reg .b16 %rs<9>;
.reg .f32 %f<146>;
.reg .b32 %r<63>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r22, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI20DoubleSlitSmallScaleEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r23, %r22, 1;
sub.s32 %r24, %r2, %r23;
mov.u32 %r25, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r26, %r4, %r22;
mad.lo.s32 %r5, %r24, %r25, %r26;
sub.s32 %r27, %r1, %r23;
mov.u32 %r28, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r29, %r6, %r22;
mad.lo.s32 %r7, %r27, %r28, %r29;
mad.lo.s32 %r8, %r7, 201, %r5;
mad.lo.s32 %r9, %r6, %r2, %r4;
setp.lt.u32 %p7, %r5, 201;
setp.lt.u32 %p8, %r7, 201;
and.pred %p1, %p8, %p7;
shl.b32 %r30, %r9, 2;
mov.u32 %r31, shmem;
add.s32 %r10, %r31, %r30;
shl.b32 %r32, %r3, 2;
add.s32 %r11, %r10, %r32;
@%p1 bra $L__BB1_2;
bra.uni $L__BB1_1;

$L__BB1_2:
cvta.to.global.u64 %rd5, %rd1;
mul.wide.s32 %rd6, %r8, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r10], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r11], %f17;
bra.uni $L__BB1_3;

$L__BB1_1:
mov.u32 %r33, 0;
st.shared.u32 [%r10], %r33;
st.shared.u32 [%r11], %r33;

$L__BB1_3:
bar.sync 0;
setp.lt.s32 %p9, %r22, 1;
@%p9 bra $L__BB1_38;

setp.eq.s32 %p2, %r7, 0;
mov.u32 %r62, 0;
add.s32 %r35, %r9, %r3;
shl.b32 %r36, %r35, 2;
add.s32 %r12, %r31, %r36;
cvt.rn.f32.s32 %f1, %r7;
setp.ne.s32 %p10, %r7, 100;
setp.ne.s32 %p11, %r5, 33;
or.pred %p3, %p10, %p11;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r38, %r3, %r2;
shl.b32 %r41, %r38, 2;
add.s32 %r13, %r10, %r41;
shl.b32 %r42, %r2, 2;
add.s32 %r14, %r12, %r42;
and.b32 %r15, %r22, 1;
setp.eq.s32 %p12, %r22, 1;
@%p12 bra $L__BB1_27;

sub.s32 %r61, %r22, %r15;
mov.u32 %r62, 0;

$L__BB1_6:
mov.pred %p95, -1;
setp.eq.s32 %p14, %r5, 0;
@%p14 bra $L__BB1_9;

setp.eq.s32 %p15, %r5, 200;
@%p15 bra $L__BB1_9;

mov.pred %p95, %p2;

$L__BB1_9:
not.b32 %r44, %r62;
setp.eq.s32 %p16, %r7, 200;
or.pred %p17, %p16, %p95;
add.s32 %r45, %r1, %r44;
setp.lt.u32 %p18, %r6, %r45;
setp.gt.s32 %p19, %r6, %r62;
setp.gt.s32 %p20, %r4, %r62;
add.s32 %r46, %r2, %r44;
setp.lt.u32 %p21, %r4, %r46;
and.pred %p22, %p20, %p21;
and.pred %p23, %p19, %p22;
and.pred %p24, %p18, %p23;
and.pred %p25, %p1, %p24;
not.pred %p26, %p25;
or.pred %p27, %p17, %p26;
mov.f32 %f143, 0f00000000;
@%p27 bra $L__BB1_16;

setp.ne.s32 %p28, %r5, 133;
mov.f32 %f19, 0f43480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p28 bra $L__BB1_12;

setp.ltu.ftz.f32 %p29, %f3, 0f3EDEB830;
setp.gtu.ftz.f32 %p30, %f3, 0f3F10A3E8;
setp.ltu.ftz.f32 %p31, %f3, 0f3F08F5B2;
or.pred %p32, %p30, %p31;
setp.gtu.ftz.f32 %p33, %f3, 0f3EEE149C;
or.pred %p34, %p33, %p29;
and.pred %p35, %p32, %p34;
selp.u16 %rs7, 1, 0, %p35;

$L__BB1_12:
setp.ne.s16 %p36, %rs7, 0;
@%p36 bra $L__BB1_16;

@%p3 bra $L__BB1_15;
bra.uni $L__BB1_14;

$L__BB1_15:
mov.f32 %f25, 0f43480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r12];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r10];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r12+4];
ld.shared.f32 %f52, [%r12+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r13];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r14];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f143, %f57, 0f3D800000, %f50;
bra.uni $L__BB1_16;

$L__BB1_14:
add.s32 %r47, %r62, 1;
cvt.rn.f32.s32 %f21, %r47;
fma.rn.ftz.f32 %f22, %f21, 0f3AA3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f143, %f24, 0f41200000;

$L__BB1_16:
bar.sync 0;
ld.shared.f32 %f58, [%r12];
st.shared.f32 [%r10], %f58;
st.shared.f32 [%r12], %f143;
bar.sync 0;
mov.pred %p96, -1;
@%p14 bra $L__BB1_19;

setp.eq.s32 %p39, %r5, 200;
@%p39 bra $L__BB1_19;

mov.pred %p96, %p2;

$L__BB1_19:
add.s32 %r48, %r62, 1;
mov.u32 %r49, -2;
sub.s32 %r50, %r49, %r62;
or.pred %p41, %p16, %p96;
add.s32 %r51, %r1, %r50;
setp.lt.u32 %p42, %r6, %r51;
setp.gt.s32 %p43, %r6, %r48;
add.s32 %r52, %r2, %r50;
setp.lt.u32 %p44, %r4, %r52;
setp.gt.s32 %p45, %r4, %r48;
and.pred %p46, %p45, %p44;
and.pred %p47, %p43, %p46;
and.pred %p48, %p42, %p47;
and.pred %p49, %p1, %p48;
not.pred %p50, %p49;
or.pred %p51, %p41, %p50;
mov.f32 %f144, 0f00000000;
@%p51 bra $L__BB1_26;

setp.ne.s32 %p52, %r5, 133;
mov.f32 %f60, 0f43480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p52 bra $L__BB1_22;

setp.ltu.ftz.f32 %p53, %f7, 0f3EDEB830;
setp.gtu.ftz.f32 %p54, %f7, 0f3F10A3E8;
setp.ltu.ftz.f32 %p55, %f7, 0f3F08F5B2;
or.pred %p56, %p54, %p55;
setp.gtu.ftz.f32 %p57, %f7, 0f3EEE149C;
or.pred %p58, %p57, %p53;
and.pred %p59, %p56, %p58;
selp.u16 %rs8, 1, 0, %p59;

$L__BB1_22:
setp.ne.s16 %p60, %rs8, 0;
@%p60 bra $L__BB1_26;

@%p3 bra $L__BB1_25;
bra.uni $L__BB1_24;

$L__BB1_25:
mov.f32 %f66, 0f43480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r12];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r10];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r12+4];
ld.shared.f32 %f93, [%r12+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r13];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r14];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f144, %f98, 0f3D800000, %f91;
bra.uni $L__BB1_26;

$L__BB1_24:
add.s32 %r53, %r62, 2;
cvt.rn.f32.s32 %f62, %r53;
fma.rn.ftz.f32 %f63, %f62, 0f3AA3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f144, %f65, 0f41200000;

$L__BB1_26:
bar.sync 0;
ld.shared.f32 %f99, [%r12];
st.shared.f32 [%r10], %f99;
st.shared.f32 [%r12], %f144;
bar.sync 0;
add.s32 %r62, %r62, 2;
add.s32 %r61, %r61, -2;
setp.ne.s32 %p61, %r61, 0;
@%p61 bra $L__BB1_6;

$L__BB1_27:
setp.eq.s32 %p62, %r15, 0;
@%p62 bra $L__BB1_38;

mov.pred %p97, -1;
setp.eq.s32 %p64, %r5, 0;
@%p64 bra $L__BB1_31;

setp.eq.s32 %p65, %r5, 200;
@%p65 bra $L__BB1_31;

mov.pred %p97, %p2;

$L__BB1_31:
not.b32 %r54, %r62;
setp.eq.s32 %p66, %r7, 200;
or.pred %p67, %p66, %p97;
add.s32 %r55, %r1, %r54;
setp.lt.u32 %p68, %r6, %r55;
setp.gt.s32 %p69, %r6, %r62;
add.s32 %r56, %r2, %r54;
setp.lt.u32 %p70, %r4, %r56;
setp.gt.s32 %p71, %r4, %r62;
and.pred %p72, %p71, %p70;
and.pred %p73, %p69, %p72;
and.pred %p74, %p68, %p73;
and.pred %p75, %p1, %p74;
not.pred %p76, %p75;
or.pred %p77, %p67, %p76;
mov.f32 %f145, 0f00000000;
@%p77 bra $L__BB1_37;

setp.ne.s32 %p78, %r5, 133;
mov.f32 %f101, 0f43480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p78 bra $L__BB1_34;

setp.ltu.ftz.f32 %p79, %f11, 0f3EDEB830;
setp.gtu.ftz.f32 %p80, %f11, 0f3F10A3E8;
setp.ltu.ftz.f32 %p81, %f11, 0f3F08F5B2;
or.pred %p82, %p80, %p81;
setp.gtu.ftz.f32 %p83, %f11, 0f3EEE149C;
or.pred %p84, %p83, %p79;
and.pred %p85, %p82, %p84;
@%p85 bra $L__BB1_37;

$L__BB1_34:
@%p3 bra $L__BB1_36;
bra.uni $L__BB1_35;

$L__BB1_36:
mov.f32 %f107, 0f43480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r12];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r10];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r12+4];
ld.shared.f32 %f134, [%r12+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r13];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r14];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f145, %f139, 0f3D800000, %f132;
bra.uni $L__BB1_37;

$L__BB1_35:
add.s32 %r57, %r62, 1;
cvt.rn.f32.s32 %f103, %r57;
fma.rn.ftz.f32 %f104, %f103, 0f3AA3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f145, %f106, 0f41200000;

$L__BB1_37:
bar.sync 0;
ld.shared.f32 %f140, [%r12];
st.shared.f32 [%r10], %f140;
st.shared.f32 [%r12], %f145;
bar.sync 0;

$L__BB1_38:
setp.ge.s32 %p86, %r4, %r22;
sub.s32 %r58, %r2, %r22;
setp.lt.u32 %p87, %r4, %r58;
and.pred %p88, %p86, %p87;
setp.ge.s32 %p89, %r6, %r22;
and.pred %p90, %p89, %p88;
sub.s32 %r59, %r1, %r22;
setp.lt.u32 %p91, %r6, %r59;
and.pred %p92, %p91, %p90;
and.pred %p93, %p92, %p1;
not.pred %p94, %p93;
@%p94 bra $L__BB1_40;

ld.shared.f32 %f141, [%r10];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r8, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r11];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB1_40:
bar.sync 0;
ret;

}
//
.visible .entry _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf(
.param .f32 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1,
.param .u64 _Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2
)
{
.reg .pred %p<24>;
.reg .b16 %rs<5>;
.reg .f32 %f<47>;
.reg .b32 %r<21>;
.reg .b64 %rd<9>;


ld.param.f32 %f7, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_0];
ld.param.u64 %rd4, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_1];
ld.param.u64 %rd5, [_Z19wave_gpu_naive_stepI10DoubleSlitEvfPfPKf_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r14, %tid.x;
mad.lo.s32 %r2, %r13, %r1, %r14;
mov.u32 %r3, %ntid.y;
mov.u32 %r15, %ctaid.y;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r19, %r15, %r3, %r16;
setp.gt.s32 %p1, %r19, 3200;
@%p1 bra $L__BB2_13;

mul.ftz.f32 %f1, %f7, 0f42FB53D2;
mov.u32 %r17, %nctaid.y;
mul.lo.s32 %r5, %r3, %r17;
mov.u32 %r18, %nctaid.x;
mul.lo.s32 %r6, %r1, %r18;
cvta.to.global.u64 %rd1, %rd5;
cvta.to.global.u64 %rd2, %rd4;
sin.approx.ftz.f32 %f11, %f1;
mul.ftz.f32 %f4, %f11, 0f41200000;

$L__BB2_2:
setp.gt.s32 %p2, %r2, 3200;
@%p2 bra $L__BB2_12;

mul.lo.s32 %r8, %r19, 3201;
cvt.rn.f32.s32 %f2, %r19;
mov.u32 %r20, %r2;

$L__BB2_4:
setp.eq.s32 %p3, %r20, 3200;
setp.eq.s32 %p4, %r20, 0;
or.pred %p5, %p4, %p3;
setp.eq.s32 %p6, %r19, 0;
or.pred %p7, %p6, %p5;
setp.eq.s32 %p8, %r19, 3200;
or.pred %p9, %p8, %p7;
add.s32 %r10, %r20, %r8;
mul.wide.s32 %rd6, %r10, 4;
add.s64 %rd3, %rd2, %rd6;
mov.f32 %f46, 0f00000000;
@%p9 bra $L__BB2_11;

mov.f32 %f9, 0f45480000;
div.approx.ftz.f32 %f3, %f2, %f9;
setp.ne.s32 %p10, %r20, 2133;
mov.u16 %rs4, 0;
@%p10 bra $L__BB2_7;

setp.ltu.ftz.f32 %p11, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p12, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p13, %f3, 0f3F08F5C3;
or.pred %p14, %p12, %p13;
setp.gtu.ftz.f32 %p15, %f3, 0f3EEE147A;
or.pred %p16, %p15, %p11;
and.pred %p17, %p14, %p16;
selp.u16 %rs4, 1, 0, %p17;

$L__BB2_7:
setp.ne.s16 %p18, %rs4, 0;
@%p18 bra $L__BB2_11;

setp.ne.s32 %p19, %r19, 1600;
setp.ne.s32 %p20, %r20, 533;
or.pred %p21, %p20, %p19;
@%p21 bra $L__BB2_10;
bra.uni $L__BB2_9;

$L__BB2_10:
cvt.rn.f32.s32 %f12, %r20;
mov.f32 %f13, 0f45480000;
div.approx.ftz.f32 %f14, %f12, %f13;
mov.f32 %f15, 0f3F800000;
sub.ftz.f32 %f16, %f15, %f14;
min.ftz.f32 %f17, %f14, %f16;
mov.f32 %f18, 0f3DCCCCCD;
min.ftz.f32 %f19, %f17, %f18;
div.approx.ftz.f32 %f20, %f19, %f18;
sub.ftz.f32 %f21, %f15, %f20;
sub.ftz.f32 %f22, %f15, %f3;
min.ftz.f32 %f23, %f3, %f22;
min.ftz.f32 %f24, %f23, %f18;
div.approx.ftz.f32 %f25, %f24, %f18;
sub.ftz.f32 %f26, %f15, %f25;
max.ftz.f32 %f27, %f21, %f26;
mul.ftz.f32 %f28, %f27, 0f3F000000;
mul.ftz.f32 %f29, %f27, %f28;
mov.f32 %f30, 0f40000000;
sub.ftz.f32 %f31, %f30, %f29;
add.ftz.f32 %f32, %f31, 0fBE800000;
add.s64 %rd8, %rd1, %rd6;
ld.global.f32 %f33, [%rd8];
mul.ftz.f32 %f34, %f33, %f32;
sub.ftz.f32 %f35, %f15, %f29;
ld.global.f32 %f36, [%rd3];
mul.ftz.f32 %f37, %f36, %f35;
sub.ftz.f32 %f38, %f34, %f37;
ld.global.f32 %f39, [%rd8+4];
ld.global.f32 %f40, [%rd8+-4];
add.ftz.f32 %f41, %f40, %f39;
ld.global.f32 %f42, [%rd8+-12804];
add.ftz.f32 %f43, %f41, %f42;
ld.global.f32 %f44, [%rd8+12804];
add.ftz.f32 %f45, %f43, %f44;
fma.rn.ftz.f32 %f46, %f45, 0f3D800000, %f38;
bra.uni $L__BB2_11;

$L__BB2_9:
mov.f32 %f46, %f4;

$L__BB2_11:
st.global.f32 [%rd3], %f46;
add.s32 %r20, %r20, %r6;
setp.lt.s32 %p22, %r20, 3201;
@%p22 bra $L__BB2_4;

$L__BB2_12:
add.s32 %r19, %r19, %r5;
setp.lt.s32 %p23, %r19, 3201;
@%p23 bra $L__BB2_2;

$L__BB2_13:
ret;

}
//
.visible .entry _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1_(
.param .f32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0,
.param .u32 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4,
.param .u64 _Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5
)
{
.reg .pred %p<98>;
.reg .b16 %rs<9>;
.reg .f32 %f<146>;
.reg .b32 %r<63>;
.reg .b64 %rd<15>;


ld.param.f32 %f15, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_0];
ld.param.u32 %r22, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_1];
ld.param.u64 %rd1, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_2];
ld.param.u64 %rd2, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_3];
ld.param.u64 %rd3, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_4];
ld.param.u64 %rd4, [_Z24wave_gpu_shmem_multistepI10DoubleSlitEvfjPfPKfS1_S1__param_5];
mov.u32 %r1, %ntid.y;
mov.u32 %r2, %ntid.x;
mul.lo.s32 %r3, %r2, %r1;
shl.b32 %r23, %r22, 1;
sub.s32 %r24, %r2, %r23;
mov.u32 %r25, %ctaid.x;
mov.u32 %r4, %tid.x;
sub.s32 %r26, %r4, %r22;
mad.lo.s32 %r5, %r24, %r25, %r26;
sub.s32 %r27, %r1, %r23;
mov.u32 %r28, %ctaid.y;
mov.u32 %r6, %tid.y;
sub.s32 %r29, %r6, %r22;
mad.lo.s32 %r7, %r27, %r28, %r29;
mad.lo.s32 %r8, %r7, 3201, %r5;
mad.lo.s32 %r9, %r6, %r2, %r4;
setp.lt.u32 %p7, %r5, 3201;
setp.lt.u32 %p8, %r7, 3201;
and.pred %p1, %p8, %p7;
shl.b32 %r30, %r9, 2;
mov.u32 %r31, shmem;
add.s32 %r10, %r31, %r30;
shl.b32 %r32, %r3, 2;
add.s32 %r11, %r10, %r32;
@%p1 bra $L__BB3_2;
bra.uni $L__BB3_1;

$L__BB3_2:
cvta.to.global.u64 %rd5, %rd1;
mul.wide.s32 %rd6, %r8, 4;
add.s64 %rd7, %rd5, %rd6;
ld.global.f32 %f16, [%rd7];
st.shared.f32 [%r10], %f16;
cvta.to.global.u64 %rd8, %rd2;
add.s64 %rd9, %rd8, %rd6;
ld.global.f32 %f17, [%rd9];
st.shared.f32 [%r11], %f17;
bra.uni $L__BB3_3;

$L__BB3_1:
mov.u32 %r33, 0;
st.shared.u32 [%r10], %r33;
st.shared.u32 [%r11], %r33;

$L__BB3_3:
bar.sync 0;
setp.lt.s32 %p9, %r22, 1;
@%p9 bra $L__BB3_38;

setp.eq.s32 %p2, %r7, 0;
mov.u32 %r62, 0;
add.s32 %r35, %r9, %r3;
shl.b32 %r36, %r35, 2;
add.s32 %r12, %r31, %r36;
cvt.rn.f32.s32 %f1, %r7;
setp.ne.s32 %p10, %r7, 1600;
setp.ne.s32 %p11, %r5, 533;
or.pred %p3, %p10, %p11;
cvt.rn.f32.s32 %f2, %r5;
sub.s32 %r38, %r3, %r2;
shl.b32 %r41, %r38, 2;
add.s32 %r13, %r10, %r41;
shl.b32 %r42, %r2, 2;
add.s32 %r14, %r12, %r42;
and.b32 %r15, %r22, 1;
setp.eq.s32 %p12, %r22, 1;
@%p12 bra $L__BB3_27;

sub.s32 %r61, %r22, %r15;
mov.u32 %r62, 0;

$L__BB3_6:
mov.pred %p95, -1;
setp.eq.s32 %p14, %r5, 0;
@%p14 bra $L__BB3_9;

setp.eq.s32 %p15, %r5, 3200;
@%p15 bra $L__BB3_9;

mov.pred %p95, %p2;

$L__BB3_9:
not.b32 %r44, %r62;
setp.eq.s32 %p16, %r7, 3200;
or.pred %p17, %p16, %p95;
add.s32 %r45, %r1, %r44;
setp.lt.u32 %p18, %r6, %r45;
setp.gt.s32 %p19, %r6, %r62;
setp.gt.s32 %p20, %r4, %r62;
add.s32 %r46, %r2, %r44;
setp.lt.u32 %p21, %r4, %r46;
and.pred %p22, %p20, %p21;
and.pred %p23, %p19, %p22;
and.pred %p24, %p18, %p23;
and.pred %p25, %p1, %p24;
not.pred %p26, %p25;
or.pred %p27, %p17, %p26;
mov.f32 %f143, 0f00000000;
@%p27 bra $L__BB3_16;

setp.ne.s32 %p28, %r5, 2133;
mov.f32 %f19, 0f45480000;
div.approx.ftz.f32 %f3, %f1, %f19;
mov.u16 %rs7, 0;
@%p28 bra $L__BB3_12;

setp.ltu.ftz.f32 %p29, %f3, 0f3EDEB852;
setp.gtu.ftz.f32 %p30, %f3, 0f3F10A3D7;
setp.ltu.ftz.f32 %p31, %f3, 0f3F08F5C3;
or.pred %p32, %p30, %p31;
setp.gtu.ftz.f32 %p33, %f3, 0f3EEE147A;
or.pred %p34, %p33, %p29;
and.pred %p35, %p32, %p34;
selp.u16 %rs7, 1, 0, %p35;

$L__BB3_12:
setp.ne.s16 %p36, %rs7, 0;
@%p36 bra $L__BB3_16;

@%p3 bra $L__BB3_15;
bra.uni $L__BB3_14;

$L__BB3_15:
mov.f32 %f25, 0f45480000;
div.approx.ftz.f32 %f26, %f2, %f25;
mov.f32 %f27, 0f3F800000;
sub.ftz.f32 %f28, %f27, %f26;
min.ftz.f32 %f29, %f26, %f28;
mov.f32 %f30, 0f3DCCCCCD;
min.ftz.f32 %f31, %f29, %f30;
div.approx.ftz.f32 %f32, %f31, %f30;
sub.ftz.f32 %f33, %f27, %f32;
sub.ftz.f32 %f34, %f27, %f3;
min.ftz.f32 %f35, %f3, %f34;
min.ftz.f32 %f36, %f35, %f30;
div.approx.ftz.f32 %f37, %f36, %f30;
sub.ftz.f32 %f38, %f27, %f37;
max.ftz.f32 %f39, %f33, %f38;
mul.ftz.f32 %f40, %f39, 0f3F000000;
mul.ftz.f32 %f41, %f39, %f40;
mov.f32 %f42, 0f40000000;
sub.ftz.f32 %f43, %f42, %f41;
add.ftz.f32 %f44, %f43, 0fBE800000;
ld.shared.f32 %f45, [%r12];
mul.ftz.f32 %f46, %f45, %f44;
sub.ftz.f32 %f47, %f27, %f41;
ld.shared.f32 %f48, [%r10];
mul.ftz.f32 %f49, %f48, %f47;
sub.ftz.f32 %f50, %f46, %f49;
ld.shared.f32 %f51, [%r12+4];
ld.shared.f32 %f52, [%r12+-4];
add.ftz.f32 %f53, %f52, %f51;
ld.shared.f32 %f54, [%r13];
add.ftz.f32 %f55, %f53, %f54;
ld.shared.f32 %f56, [%r14];
add.ftz.f32 %f57, %f55, %f56;
fma.rn.ftz.f32 %f143, %f57, 0f3D800000, %f50;
bra.uni $L__BB3_16;

$L__BB3_14:
add.s32 %r47, %r62, 1;
cvt.rn.f32.s32 %f21, %r47;
fma.rn.ftz.f32 %f22, %f21, 0f38A3D70A, %f15;
mul.ftz.f32 %f23, %f22, 0f42FB53D2;
sin.approx.ftz.f32 %f24, %f23;
mul.ftz.f32 %f143, %f24, 0f41200000;

$L__BB3_16:
bar.sync 0;
ld.shared.f32 %f58, [%r12];
st.shared.f32 [%r10], %f58;
st.shared.f32 [%r12], %f143;
bar.sync 0;
mov.pred %p96, -1;
@%p14 bra $L__BB3_19;

setp.eq.s32 %p39, %r5, 3200;
@%p39 bra $L__BB3_19;

mov.pred %p96, %p2;

$L__BB3_19:
add.s32 %r48, %r62, 1;
mov.u32 %r49, -2;
sub.s32 %r50, %r49, %r62;
or.pred %p41, %p16, %p96;
add.s32 %r51, %r1, %r50;
setp.lt.u32 %p42, %r6, %r51;
setp.gt.s32 %p43, %r6, %r48;
add.s32 %r52, %r2, %r50;
setp.lt.u32 %p44, %r4, %r52;
setp.gt.s32 %p45, %r4, %r48;
and.pred %p46, %p45, %p44;
and.pred %p47, %p43, %p46;
and.pred %p48, %p42, %p47;
and.pred %p49, %p1, %p48;
not.pred %p50, %p49;
or.pred %p51, %p41, %p50;
mov.f32 %f144, 0f00000000;
@%p51 bra $L__BB3_26;

setp.ne.s32 %p52, %r5, 2133;
mov.f32 %f60, 0f45480000;
div.approx.ftz.f32 %f7, %f1, %f60;
mov.u16 %rs8, 0;
@%p52 bra $L__BB3_22;

setp.ltu.ftz.f32 %p53, %f7, 0f3EDEB852;
setp.gtu.ftz.f32 %p54, %f7, 0f3F10A3D7;
setp.ltu.ftz.f32 %p55, %f7, 0f3F08F5C3;
or.pred %p56, %p54, %p55;
setp.gtu.ftz.f32 %p57, %f7, 0f3EEE147A;
or.pred %p58, %p57, %p53;
and.pred %p59, %p56, %p58;
selp.u16 %rs8, 1, 0, %p59;

$L__BB3_22:
setp.ne.s16 %p60, %rs8, 0;
@%p60 bra $L__BB3_26;

@%p3 bra $L__BB3_25;
bra.uni $L__BB3_24;

$L__BB3_25:
mov.f32 %f66, 0f45480000;
div.approx.ftz.f32 %f67, %f2, %f66;
mov.f32 %f68, 0f3F800000;
sub.ftz.f32 %f69, %f68, %f67;
min.ftz.f32 %f70, %f67, %f69;
mov.f32 %f71, 0f3DCCCCCD;
min.ftz.f32 %f72, %f70, %f71;
div.approx.ftz.f32 %f73, %f72, %f71;
sub.ftz.f32 %f74, %f68, %f73;
sub.ftz.f32 %f75, %f68, %f7;
min.ftz.f32 %f76, %f7, %f75;
min.ftz.f32 %f77, %f76, %f71;
div.approx.ftz.f32 %f78, %f77, %f71;
sub.ftz.f32 %f79, %f68, %f78;
max.ftz.f32 %f80, %f74, %f79;
mul.ftz.f32 %f81, %f80, 0f3F000000;
mul.ftz.f32 %f82, %f80, %f81;
mov.f32 %f83, 0f40000000;
sub.ftz.f32 %f84, %f83, %f82;
add.ftz.f32 %f85, %f84, 0fBE800000;
ld.shared.f32 %f86, [%r12];
mul.ftz.f32 %f87, %f86, %f85;
sub.ftz.f32 %f88, %f68, %f82;
ld.shared.f32 %f89, [%r10];
mul.ftz.f32 %f90, %f89, %f88;
sub.ftz.f32 %f91, %f87, %f90;
ld.shared.f32 %f92, [%r12+4];
ld.shared.f32 %f93, [%r12+-4];
add.ftz.f32 %f94, %f93, %f92;
ld.shared.f32 %f95, [%r13];
add.ftz.f32 %f96, %f94, %f95;
ld.shared.f32 %f97, [%r14];
add.ftz.f32 %f98, %f96, %f97;
fma.rn.ftz.f32 %f144, %f98, 0f3D800000, %f91;
bra.uni $L__BB3_26;

$L__BB3_24:
add.s32 %r53, %r62, 2;
cvt.rn.f32.s32 %f62, %r53;
fma.rn.ftz.f32 %f63, %f62, 0f38A3D70A, %f15;
mul.ftz.f32 %f64, %f63, 0f42FB53D2;
sin.approx.ftz.f32 %f65, %f64;
mul.ftz.f32 %f144, %f65, 0f41200000;

$L__BB3_26:
bar.sync 0;
ld.shared.f32 %f99, [%r12];
st.shared.f32 [%r10], %f99;
st.shared.f32 [%r12], %f144;
bar.sync 0;
add.s32 %r62, %r62, 2;
add.s32 %r61, %r61, -2;
setp.ne.s32 %p61, %r61, 0;
@%p61 bra $L__BB3_6;

$L__BB3_27:
setp.eq.s32 %p62, %r15, 0;
@%p62 bra $L__BB3_38;

mov.pred %p97, -1;
setp.eq.s32 %p64, %r5, 0;
@%p64 bra $L__BB3_31;

setp.eq.s32 %p65, %r5, 3200;
@%p65 bra $L__BB3_31;

mov.pred %p97, %p2;

$L__BB3_31:
not.b32 %r54, %r62;
setp.eq.s32 %p66, %r7, 3200;
or.pred %p67, %p66, %p97;
add.s32 %r55, %r1, %r54;
setp.lt.u32 %p68, %r6, %r55;
setp.gt.s32 %p69, %r6, %r62;
add.s32 %r56, %r2, %r54;
setp.lt.u32 %p70, %r4, %r56;
setp.gt.s32 %p71, %r4, %r62;
and.pred %p72, %p71, %p70;
and.pred %p73, %p69, %p72;
and.pred %p74, %p68, %p73;
and.pred %p75, %p1, %p74;
not.pred %p76, %p75;
or.pred %p77, %p67, %p76;
mov.f32 %f145, 0f00000000;
@%p77 bra $L__BB3_37;

setp.ne.s32 %p78, %r5, 2133;
mov.f32 %f101, 0f45480000;
div.approx.ftz.f32 %f11, %f1, %f101;
@%p78 bra $L__BB3_34;

setp.ltu.ftz.f32 %p79, %f11, 0f3EDEB852;
setp.gtu.ftz.f32 %p80, %f11, 0f3F10A3D7;
setp.ltu.ftz.f32 %p81, %f11, 0f3F08F5C3;
or.pred %p82, %p80, %p81;
setp.gtu.ftz.f32 %p83, %f11, 0f3EEE147A;
or.pred %p84, %p83, %p79;
and.pred %p85, %p82, %p84;
@%p85 bra $L__BB3_37;

$L__BB3_34:
@%p3 bra $L__BB3_36;
bra.uni $L__BB3_35;

$L__BB3_36:
mov.f32 %f107, 0f45480000;
div.approx.ftz.f32 %f108, %f2, %f107;
mov.f32 %f109, 0f3F800000;
sub.ftz.f32 %f110, %f109, %f108;
min.ftz.f32 %f111, %f108, %f110;
mov.f32 %f112, 0f3DCCCCCD;
min.ftz.f32 %f113, %f111, %f112;
div.approx.ftz.f32 %f114, %f113, %f112;
sub.ftz.f32 %f115, %f109, %f114;
sub.ftz.f32 %f116, %f109, %f11;
min.ftz.f32 %f117, %f11, %f116;
min.ftz.f32 %f118, %f117, %f112;
div.approx.ftz.f32 %f119, %f118, %f112;
sub.ftz.f32 %f120, %f109, %f119;
max.ftz.f32 %f121, %f115, %f120;
mul.ftz.f32 %f122, %f121, 0f3F000000;
mul.ftz.f32 %f123, %f121, %f122;
mov.f32 %f124, 0f40000000;
sub.ftz.f32 %f125, %f124, %f123;
add.ftz.f32 %f126, %f125, 0fBE800000;
ld.shared.f32 %f127, [%r12];
mul.ftz.f32 %f128, %f127, %f126;
sub.ftz.f32 %f129, %f109, %f123;
ld.shared.f32 %f130, [%r10];
mul.ftz.f32 %f131, %f130, %f129;
sub.ftz.f32 %f132, %f128, %f131;
ld.shared.f32 %f133, [%r12+4];
ld.shared.f32 %f134, [%r12+-4];
add.ftz.f32 %f135, %f134, %f133;
ld.shared.f32 %f136, [%r13];
add.ftz.f32 %f137, %f135, %f136;
ld.shared.f32 %f138, [%r14];
add.ftz.f32 %f139, %f137, %f138;
fma.rn.ftz.f32 %f145, %f139, 0f3D800000, %f132;
bra.uni $L__BB3_37;

$L__BB3_35:
add.s32 %r57, %r62, 1;
cvt.rn.f32.s32 %f103, %r57;
fma.rn.ftz.f32 %f104, %f103, 0f38A3D70A, %f15;
mul.ftz.f32 %f105, %f104, 0f42FB53D2;
sin.approx.ftz.f32 %f106, %f105;
mul.ftz.f32 %f145, %f106, 0f41200000;

$L__BB3_37:
bar.sync 0;
ld.shared.f32 %f140, [%r12];
st.shared.f32 [%r10], %f140;
st.shared.f32 [%r12], %f145;
bar.sync 0;

$L__BB3_38:
setp.ge.s32 %p86, %r4, %r22;
sub.s32 %r58, %r2, %r22;
setp.lt.u32 %p87, %r4, %r58;
and.pred %p88, %p86, %p87;
setp.ge.s32 %p89, %r6, %r22;
and.pred %p90, %p89, %p88;
sub.s32 %r59, %r1, %r22;
setp.lt.u32 %p91, %r6, %r59;
and.pred %p92, %p91, %p90;
and.pred %p93, %p92, %p1;
not.pred %p94, %p93;
@%p94 bra $L__BB3_40;

ld.shared.f32 %f141, [%r10];
cvta.to.global.u64 %rd10, %rd3;
mul.wide.s32 %rd11, %r8, 4;
add.s64 %rd12, %rd10, %rd11;
st.global.f32 [%rd12], %f141;
ld.shared.f32 %f142, [%r11];
cvta.to.global.u64 %rd13, %rd4;
add.s64 %rd14, %rd13, %rd11;
st.global.f32 [%rd14], %f142;

$L__BB3_40:
bar.sync 0;
ret;

}


